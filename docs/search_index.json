[
["index.html", "ログデータ処理で始めるlubridate入門 はじめに 参考資料", " ログデータ処理で始めるlubridate入門 前田和寛(@kazutan) 2018-02-24 はじめに これはSappoRo.R #8 にて同タイトルで発表した内容です。本編は次のページ以降になります 参考資料 lubridateパッケージの本家サイト Dates and Times Cheat Sheet(pdf注意) "],
["01-lubridate.html", "lesson: 1 lubridateパッケージ 1.1 lubridateパッケージとは 1.2 インストールと読み込み 1.3 日付や時刻の処理 1.4 参照", " lesson: 1 lubridateパッケージ 1.1 lubridateパッケージとは lubridateパッケージとは、日時データの処理に特化したパッケージです。いわゆるtidyverseパッケージ群に含まれます。 (lubridateパッケージの特徴) 1.2 インストールと読み込み インストールは以下の方法で可能です: # CRAN版 install.packages(&quot;lubridate&quot;) # GitHub版 remotes::install_github(&quot;tidyverse/lubridate&quot;) # githubinstallからでもOK githubinstall::githubinstall(&quot;lubridate&quot;) パッケージの読み込みもいつも通りです: library(lubridate) #&gt; #&gt; Attaching package: &#39;lubridate&#39; #&gt; The following object is masked from &#39;package:base&#39;: #&gt; #&gt; date 1.3 日付や時刻の処理 このlubridateは非常に様々な機能を提供します。まずは日付や時刻のparseについて見てみましょう。 1.3.1 日付データ データセットを読み込んだ時、日付を表す変数が文字列として処理されるのはよくある話です。Rはこの文字列として表現されている文字列を日付型に変換する方法はいくつかありますが、lubridateはymd()といった関数でシンプルに変換します: ymd(&quot;2018-02-24&quot;) #&gt; [1] &quot;2018-02-24&quot; このymd()は、Year, Month, Dayの頭文字で非常に直感的です。この例だと、この形式でしか対応していないように見えます。ですがこの関数はだいたいそれっぽい文字列だったらperseしてしまうという強さがあります。?ymdにある例を使って示します: x &lt;- c(20090101, &quot;2009-01-02&quot;, &quot;2009 01 03&quot;, &quot;2009-1-4&quot;, &quot;2009-1, 5&quot;, &quot;Created on 2009 1 6&quot;, &quot;200901 !!! 07&quot;) ymd(x) #&gt; [1] &quot;2009-01-01&quot; &quot;2009-01-02&quot; &quot;2009-01-03&quot; &quot;2009-01-04&quot; &quot;2009-01-05&quot; #&gt; [6] &quot;2009-01-06&quot; &quot;2009-01-07&quot; parseできるかどうかの目安として、“年”, “月”, “日”にできそうな数値要素があり、それが弁別できそうな場合です。なので“月”と“日”だけだとうまくいきません。うまくいかないパターンについては?ymdのドキュメントを参照してください。 また、年月日の並びでなくてもparseしてくれる関数が準備されています: dmy(010210) #&gt; [1] &quot;2010-02-01&quot; mdy(010210) #&gt; [1] &quot;2010-01-02&quot; このような感じで“y”,“m”,“d”を並び替えれば思う通りにできるでしょう。 1.3.2 時刻データ 時刻データについても、日付のparse関数と同じように準備されています: hms(&quot;10:20:30&quot;) #&gt; [1] &quot;10H 20M 30S&quot; 考え方はymd()と同様なので省略しますが、一度?hmsを読んでください。 1.3.3 日付&amp;時刻データ 両方を合わせたデータにしたい場合は、以下のようにします: ymd_hms(&quot;2018-2-24 15:30:15&quot;) #&gt; [1] &quot;2018-02-24 15:30:15 UTC&quot; このymd_hms()はPOSIXct形式の日付ー時刻データオブジェクトを返します。つまり1970-01-01が基準になります。また、タイムゾーンはUTCがデフォルトとなります。タイムゾーンを指定したい場合はtz=オプションで指定します: ymd_hms(&quot;2018-2-24 15:30:15&quot;, tz=&quot;Asia/Tokyo&quot;) #&gt; [1] &quot;2018-02-24 15:30:15 JST&quot; 1.3.4 柔軟なフォーマットに対応するには よくある形ではなく、かなり独自なフォーマットで日時データを作成している場合もあるでしょう。そのような時にはparse_date_time()などを使うとできます。詳細は省略しますが、ymd_hms()などでうまく行かない問は?parse_date_time()をチェックしてみて試してみてください。従来のR関数群で処理するよりもうまくいけるでしょう。 1.4 参照 Parse dates with year, month, and day components ymd()など日付データparserの解説 Parse periods with hour, minute, and second components hms()など時刻データparserの解説 Parse date-times with year, month, and day, hour, minute, and second components. ymd_hmsなど日時データparserの解説 User friendly date-time parsing functions parse_date_time()など柔軟な日時データフォーマットに対応する関数の解説 "],
["02-makelog_duration.html", "lesson: 2 仮想ログデータ生成 2.1 想定シナリオ 2.2 データ生成 2.3 参照", " lesson: 2 仮想ログデータ生成 ここでは、これから使用していくための仮想ログデータを作成します。またこのログデータ作成を通じて、lubridateのperiodpオブジェクトについて紹介します。 2.1 想定シナリオ 準備するログデータは以下のようなシナリオとします: あるサービスのアイテム購入履歴ログデータ 2018年1月1日から50日間のデータ 購入は24時間常に発生 発生確率は(めんどうなので)一様とする アイテム名はitem1-5の5種類 価格は順に100, 500, 1000, 2000, 5000 購入発生比は順に100, 50, 10, 5, 2 会員IDは1000001:1000300の300名 何度でも購入可能 ログデータの設計は以下の通り stamp: タイムスタンプ id: 会員ID value: 購入金額 item: 項目ラベル 今回は50日間で10000件の購入があったと仮定 2.2 データ生成 上記シナリオにあうようにデータを生成します。 2.2.1 Rコード 必要なパッケージを読み込みます。 library(tidyverse) #&gt; ─ Attaching packages ──────────────────── tidyverse 1.2.1 ─ #&gt; ✔ ggplot2 2.2.1 ✔ purrr 0.2.4 #&gt; ✔ tibble 1.4.2 ✔ dplyr 0.7.4 #&gt; ✔ tidyr 0.8.0 ✔ stringr 1.3.0 #&gt; ✔ readr 1.1.1 ✔ forcats 0.3.0 #&gt; ─ Conflicts ────────────────────── tidyverse_conflicts() ─ #&gt; ✖ lubridate::as.difftime() masks base::as.difftime() #&gt; ✖ lubridate::date() masks base::date() #&gt; ✖ dplyr::filter() masks stats::filter() #&gt; ✖ lubridate::intersect() masks base::intersect() #&gt; ✖ dplyr::lag() masks stats::lag() #&gt; ✖ lubridate::setdiff() masks base::setdiff() #&gt; ✖ lubridate::union() masks base::union() library(lubridate) パラメータを設定します。 start &lt;- &quot;2018-1-1 00:00:00&quot; #開始日 n &lt;- 10000 # 購入件数 duration_days &lt;- 50 # ログの期間(日数) list_price &lt;- c(100, 500, 1000, 2000, 5000) # アイテムの価格リスト list_item &lt;- paste(&quot;item&quot;, 1:length(list_price), sep = &quot;_&quot;) # アイテムリスト list_item_p &lt;- c(100, 50, 10, 5, 2) # 発生比 list_id &lt;- 1000001:1000300 # 会員id ログデータのdata.frameを生成します。今回はdf_logというオブジェクトとします。 df_log &lt;- data.frame( # タイムスタンプを作成 # 開始日時を生成 stamp = ymd_hms(start) + # 0-50までの整数からランダムに10000件生成し、それを日数データに変換して足す days(sample(0:duration_days, n, replace = TRUE)) + # 0-23までの整数からランダムに10000件生成し、それを時間データに変換して足す hours(sample(0:23, n, replace = TRUE)) + # 0-59までの整数からランダムに10000件生成し、それを分データに変換して足す minutes(sample(0:59, n, replace = TRUE)) + # 0-59までの整数からランダムに10000件生成し、それを病データに変換して足す seconds(sample(0:59, n, replace = TRUE)), # 会員IDをランダムに生成 id = sample(list_id, n, replace = TRUE), # アイテム名をランダムに生成 item = sample(list_item, n, replace = TRUE, prob = list_item_p) ) %&gt;% # ログデータっぽく、タイムスタンプで並べ替える arrange(stamp) ここまでの処理で、以下のようなデータができます: knitr::kable(sample_n(df_log, 10)) stamp id item 3954 2018-01-21 08:07:26 1000057 item_2 5733 2018-01-30 12:11:20 1000131 item_1 4285 2018-01-23 00:38:05 1000088 item_2 1881 2018-01-10 22:09:17 1000055 item_1 7720 2018-02-09 08:39:21 1000188 item_2 252 2018-01-02 07:19:54 1000090 item_1 5229 2018-01-27 22:40:43 1000110 item_2 2796 2018-01-15 11:47:17 1000042 item_1 2380 2018-01-13 09:58:16 1000243 item_1 4921 2018-01-26 06:52:28 1000086 item_1 アイテム名(item)に対応する価格(value)を当てます。 # 置換用の名前付きベクトルを作成 # 置換前文字列がnames, 置換後の文字列がベクトルの内容となるように pat &lt;- as.character(list_price) names(pat) &lt;- list_item # itemを正規表現で置換して数値に変換し、列として追加 df_log &lt;- df_log %&gt;% # 対応する項目を一気に置換して整数型へ変換 # この変換方法については?stringr::str_replace_allを参照 mutate(value = str_replace_all(item, pat) %&gt;% as.numeric()) 生成したdf_logの一部を表示します: knitr::kable(sample_n(df_log, 10)) stamp id item value 7530 2018-02-08 11:16:31 1000172 item_1 100 3646 2018-01-19 20:16:06 1000243 item_1 100 4070 2018-01-21 21:54:21 1000063 item_3 1000 3034 2018-01-16 16:16:03 1000143 item_3 1000 4262 2018-01-22 21:01:11 1000078 item_1 100 2394 2018-01-13 11:28:59 1000183 item_1 100 153 2018-01-01 19:10:26 1000083 item_1 100 9742 2018-02-19 16:02:05 1000024 item_2 500 7773 2018-02-09 15:48:54 1000008 item_1 100 8060 2018-02-11 02:55:54 1000156 item_2 500 これで仮想ログデータが完成です。一応csvに出力しときます: readr::write_csv(df_log, path = &quot;df_log.csv&quot;) 2.2.2 解説 ここでのポイントはタイムスタンプ(stamp)の生成です。今回は開始日時(2018-1-1 00:00:00)から50日間でランダムに生成させる必要があります。そこで利用したのがdays()などのperiodオブジェクトを生成する関数です。 periodオブジェクトは、lubridateパッケージで準備している独自のクラスで、時間的な区間です。 # 「1日分」のperiodを生成 # 引数には整数値を指定 days(1) #&gt; [1] &quot;1d 0H 0M 0S&quot; # 負の整数だと「マイナス1日間」となる days(-1) #&gt; [1] &quot;-1d 0H 0M 0S&quot; # 足し引きもできる days(3) - days(1) #&gt; Note: method with signature &#39;Period#ANY&#39; chosen for function &#39;-&#39;, #&gt; target signature &#39;Period#Period&#39;. #&gt; &quot;ANY#Period&quot; would also be valid #&gt; [1] &quot;2d 0H 0M 0S&quot; days(3) + days(-2) #&gt; [1] &quot;1d 0H 0M 0S&quot; なぜこのようなことができるかというと、periodオブジェクトは時間的な区間を数値的に置き換えて保持しているからです。なので、日時の加算・減算ができるようになります: # 日付にperiodを加算 # この場合は日付型(Date)になる ymd(&quot;20180224&quot;) + days(3) #&gt; [1] &quot;2018-02-27&quot; # 日時にperiodを加算 # この場合はPOSIXct型になる ymd_hms(&quot;20180224 150000&quot;) + days(3) #&gt; [1] &quot;2018-02-27 15:00:00 UTC&quot; また、ベクトルでの加算・減算も可能です。ベクトルの長さが揃っていない場合はリサイクルされます: ymd(&quot;20180224&quot;) + days(1:3) #&gt; [1] &quot;2018-02-25&quot; &quot;2018-02-26&quot; &quot;2018-02-27&quot; このperiodオブジェクトはdays以外にも時間(hours())やミリ秒(miliseconds())など準備してあります。これをうまく活用し、開始日時(2018-1-1 00:00:00)へランダムな日数、時間数、秒数を足し算してタイムスタンプを作成しました。 2.3 参照 Create a period object days()などの関数の解説 "],
["03-daily_hourly.html", "lesson: 3 日別・時間別集計 3.1 想定シナリオ 3.2 処理の実行 3.3 参考資料", " lesson: 3 日別・時間別集計 ここでは、lesson2で準備したdf_logという仮想ログデータを用いて、日別集計と時間別集計を算出してまとめることを目指します。その中でlubridateによる日時データからの特定の要素(日、時間など)取り出し解説します。 3.1 想定シナリオ lesson2で作成したアイテム購入ログデータを元に日別集計を行います: 日別購入件数 日別売上合計 日別購入単価平均 この集計により、どの日に売上が多かったかなどを検証することができます。 また、同様に時間帯別集計を行います: 時間別購入件数 時間別売上合計 時間別購入単価平均 この集計により、どの時間帯で売上が多かったかなどを検証することができます。 3.2 処理の実行 3.2.1 パッケージ読み込み ここで使用するパッケージを読み込みます: library(tidyverse) library(lubridate) library(gridExtra) tidyverseは楽ですね。あと可視化用にgridExtraを使います。 3.2.2 データ読み込み lesson2で作成したcsvを読み込みます。readr::read_csv()を使います: df_log &lt;- readr::read_csv(&quot;df_log.csv&quot;) 3.2.3 データハンドリングと可視化 3.2.3.1 日別 それぞれの日でどれだけ売上があったかを集計してデータセットにします。基本的な流れは以下のとおりです: 日時のタイムスタンプから日付の変数(date)を作成 dateごとに処理するようにグループ化 各種集計を実施 実際のRのコードは以下のようになります: df_log_date &lt;- df_log %&gt;% # 日付による丸め込みを行った変数を準備 mutate(date = date(stamp)) %&gt;% # 日付によるグループ化 group_by(date) %&gt;% # グループ化による集計 summarise( # 購入件数をカウント n_buy = n(), # 売上合計 value_buy = sum(value), # 購入単価平均 mean_buy = mean(value) ) この処理を行ったデータセットは以下のようになります: knitr::kable(head(df_log_date, 10)) date n_buy value_buy mean_buy 2018-01-01 197 72800 369.5431 2018-01-02 165 65700 398.1818 2018-01-03 188 64900 345.2128 2018-01-04 189 67700 358.2011 2018-01-05 180 77800 432.2222 2018-01-06 206 84000 407.7670 2018-01-07 195 78900 404.6154 2018-01-08 174 64300 369.5402 2018-01-09 214 85600 400.0000 2018-01-10 189 85600 452.9101 このデータを元にggplot2で可視化してみます: # ベースとなるggplotオブジェクトを作成 p_date &lt;- ggplot(df_log_date) # 日別購入件数 p_date1 &lt;- p_date + geom_line(aes(x = date, y = n_buy)) # 日別売上合計 p_date2 &lt;- p_date + geom_line(aes(x = date, y = value_buy)) # 日別購入単価平均 p_date3 &lt;- p_date + geom_line(aes(x = date, y = mean_buy)) # plotを集約 grid.arrange(p_date1, p_date2, p_date3, nrow = 2) 3.2.3.2 時間別 それぞれの時間でどれだけ売上があったかを集計してデータセットにします。基本的な流れは以下のとおりです: 日時のタイムスタンプから時間を取り出した変数(hour)を作成 hourごとに処理するようにグループ化 各種集計を実施 実際のRのコードは以下のようになります: df_log_hour &lt;- df_log %&gt;% # 時間を取り出した変数を準備 mutate(hour = hour(stamp)) %&gt;% # 時間によるグループ化 group_by(hour) %&gt;% # グループ化による集計 summarise( # 購入件数をカウント n_buy = n(), # 売上合計 value_buy = sum(value), # 購入単価平均 mean_buy = mean(value) ) この処理を行ったデータセットは以下のようになります: knitr::kable(head(df_log_hour, 10)) hour n_buy value_buy mean_buy 0 395 153400 388.3544 1 424 163200 384.9057 2 413 141300 342.1308 3 391 144000 368.2864 4 385 138900 360.7792 5 440 170400 387.2727 6 435 151200 347.5862 7 410 143900 350.9756 8 427 169800 397.6581 9 428 175700 410.5140 このデータを元にggplot2で可視化してみます: # ベースとなるggplotオブジェクトを作成 p_hour &lt;- ggplot(df_log_hour) # 時間別購入件数 p_hour1 &lt;- p_hour + geom_line(aes(x = hour, y = n_buy)) # 時間別売上合計 p_hour2 &lt;- p_hour + geom_line(aes(x = hour, y = value_buy)) # 時間別購入単価平均 p_hour3 &lt;- p_hour + geom_line(aes(x = hour, y = mean_buy)) # plotを集約 grid.arrange(p_hour1, p_hour2, p_hour3) ついでに、時間x項目でもやってみます。上との違いは、group_by()でitemも含めるところです df_log_hour_item &lt;- df_log %&gt;% mutate(hour = hour(stamp)) %&gt;% # グループ化する変数にhour, itemを指定 group_by(hour, item) %&gt;% summarise( n_buy = n(), value_buy = sum(value), mean_buy = mean(value) ) この処理を行ったデータセットは以下のようになります: knitr::kable(head(df_log_hour_item)) hour item n_buy value_buy mean_buy 0 item_1 234 23400 100 0 item_2 116 58000 500 0 item_3 27 27000 1000 0 item_4 15 30000 2000 0 item_5 3 15000 5000 1 item_1 247 24700 100 このデータを元にggplot2で可視化してみます: # 時間と項目で可視化 p_hour_item &lt;- ggplot(df_log_hour_item)+ geom_tile(aes(x = hour, y = item, fill = value_buy)) p_hour_item 3.2.4 解説 今回の処理のポイントは、日時データから特定の要素の取り出しです。lubridateには、日時データから日付や時刻を取り出す関数が要してあります。 x &lt;- ymd_hms(&quot;2018-02-24 15:30:20&quot;) # 年の取り出し year(x) #&gt; [1] 2018 # 月の取り出し month(x) #&gt; [1] 2 # 日の取り出し day(x) #&gt; [1] 24 # 時間の取り出し hour(x) #&gt; [1] 15 これらはすべて数値型となります。また、日時データから日付型のデータを取得したい場合は、date()を使ってください: date(x) #&gt; [1] &quot;2018-02-24&quot; こちらを利用すると、日付データが返ってきます。それぞれ用途によって使い分けるといいでしょう。 また、日時データの丸め込み関数もいろいろ準備されていますが、ここでは省略します。 3.3 参考資料 Get/set years component of a date-time 年を取り出すyear()の説明。 Get/set hours component of a date-time 時間を取得するhour()の説明 Get/set date component of a date-time lubridateのdate関数の説明 "],
["04-wday_week.html", "lesson: 4 曜日別・週別集計 4.1 想定シナリオ 4.2 処理の実行 4.3 参照", " lesson: 4 曜日別・週別集計 ここでは、lesson2で準備したdf_logという仮想ログデータを用いて、曜日別集計と週別集計を算出してまとめることを目指します。さらに、それらを掛けあわせたデータセットと可視化を行います。その中でlubridateによる日時データからの特定の要素(週、曜日など)取り出し解説します。 4.1 想定シナリオ lesson2で作成したアイテム購入ログデータを元に曜日別集計を行います: 曜日別購入件数 曜日別売上合計 曜日別購入単価平均 この集計により、どの曜日に売上が多かったかなどを検証することができます。 また、同様に週間集計を行います: 週間別購入件数 週間別売上合計 週間別購入単価平均 この集計により、どの週で売上が多かったかなどを検証することができます。 4.2 処理の実行 4.2.1 パッケージ読み込み ここで使用するパッケージを読み込みます: library(tidyverse) library(lubridate) library(gridExtra) 4.2.2 データ読み込み lesson2で作成したcsvを読み込みます。readr::read_csv()を使います: df_log &lt;- readr::read_csv(&quot;df_log.csv&quot;) #&gt; Parsed with column specification: #&gt; cols( #&gt; stamp = col_datetime(format = &quot;&quot;), #&gt; id = col_integer(), #&gt; item = col_character(), #&gt; value = col_double() #&gt; ) 4.2.3 データハンドリングと可視化 4.2.3.1 曜日別 それぞれの曜日でどれだけ売上があったかを集計してデータセットにします。基本的な流れは以下のとおりです: 日時のタイムスタンプから曜日を取得して変数(weekday)を作成 weekdayごとに処理するようにグループ化 各種集計を実施 実際のRのコードは以下のようになります: df_log_wday &lt;- df_log %&gt;% # 曜日を取得して変数を追加 mutate(weekday = wday(stamp, label = TRUE, abbr = FALSE)) %&gt;% group_by(weekday) %&gt;% summarise( n_buy = n(), value_buy = sum(value), mean_buy = mean(value) ) この処理を行ったデータセットは以下のようになります: knitr::kable(df_log_wday) weekday n_buy value_buy mean_buy 日曜日 1374 560200 407.7147 月曜日 1610 600300 372.8571 火曜日 1533 616300 402.0222 水曜日 1377 526500 382.3529 木曜日 1339 510200 381.0306 金曜日 1383 546000 394.7939 土曜日 1384 518500 374.6387 このデータを元にggplot2で可視化してみます: p_wday &lt;- ggplot(df_log_wday) p_wday1 &lt;- p_wday + geom_bar(aes(x = weekday, y = n_buy), stat = &quot;identity&quot;) p_wday2 &lt;- p_wday + geom_bar(aes(x = weekday, y = value_buy), stat = &quot;identity&quot;) p_wday3 &lt;- p_wday + geom_bar(aes(x = weekday, y = mean_buy), stat = &quot;identity&quot;) grid.arrange(p_wday1, p_wday2, p_wday3) 4.2.3.2 週間 それぞれの週でどれだけ売上があったかを集計してデータセットにします。基本的な流れは以下のとおりです: 日時のタイムスタンプから週番号を取り出した変数(week)を作成 weekごとに処理するようにグループ化 各種集計を実施 実際のRのコードは以下のようになります: df_log_week &lt;- df_log %&gt;% # タイムスタンプから週番号を取得 mutate(week = week(stamp)) %&gt;% group_by(week) %&gt;% summarise( n_buy = n(), value_buy = sum(value), mean_buy = mean(value) ) この処理を行ったデータセットは以下のようになります: knitr::kable(df_log_week) week n_buy value_buy mean_buy 1 1320 511800 387.7273 2 1367 549900 402.2677 3 1395 529600 379.6416 4 1337 506600 378.9080 5 1416 537300 379.4492 6 1409 538000 381.8311 7 1361 531500 390.5217 8 395 173300 438.7342 このデータを元にggplot2で可視化してみます: p_week &lt;- ggplot(df_log_week) p_week1 &lt;- p_week + geom_bar(aes(x = week, y = n_buy), stat = &quot;identity&quot;) p_week2 &lt;- p_week + geom_bar(aes(x = week, y = value_buy), stat = &quot;identity&quot;) p_week3 &lt;- p_week + geom_bar(aes(x = week, y = mean_buy), stat = &quot;identity&quot;) grid.arrange(p_week1, p_week2, p_week3) 4.2.3.3 曜日x週 ついでに、曜日x週で集計するようにやってみます。両方の変数をgroup_by()で両方を指定すればOKです; df_log_weekday_no &lt;- df_log %&gt;% # 変数を準備 mutate(weekday = wday(stamp, label = TRUE, abbr = FALSE), week_no = week(stamp)) %&gt;% # グループ化 group_by(week_no, weekday) %&gt;% summarise( n_buy = n(), value_buy = sum(value), mean_buy = mean(value) ) この処理を行ったデータセットは以下のようになります: knitr::kable(head(df_log_weekday_no)) week_no weekday n_buy value_buy mean_buy 1 日曜日 195 78900 404.6154 1 月曜日 197 72800 369.5431 1 火曜日 165 65700 398.1818 1 水曜日 188 64900 345.2128 1 木曜日 189 67700 358.2011 1 金曜日 180 77800 432.2222 このデータを元にggplot2で可視化してみます: # 曜日と週番号で可視化 p_weekday_no &lt;- ggplot(df_log_weekday_no) p_weekday_no1 &lt;- p_weekday_no + geom_tile(aes(x = week_no, y = weekday, fill = n_buy)) p_weekday_no2 &lt;- p_weekday_no + geom_tile(aes(x = week_no, y = weekday, fill = value_buy)) p_weekday_no3 &lt;- p_weekday_no + geom_tile(aes(x = week_no, y = weekday, fill = mean_buy)) grid.arrange(p_weekday_no1, p_weekday_no2, p_weekday_no3) 4.2.4 解説 今回のポイントは、日時データから週番号および曜日を取得するところです。 週番号を取得するには、week()を利用します: x &lt;- ymd_hms(&quot;2018-02-24 15:30:20&quot;) # 週番号を取得 week(x) #&gt; [1] 8 # ついでにquaterも quarter(x) #&gt; [1] 1 # さらにsemesterも semester(x) #&gt; [1] 1 このあたりはlesson3と同様です。セメスターもクウォーターも切り出せます。開始時期も引数で指定できます。 曜日を取得するには、wday()を利用します: # 曜日を数値で取得 wday(x) #&gt; [1] 7 # 曜日を文字列(ラベル)で取得 wday(x, label = TRUE) #&gt; [1] 土 #&gt; Levels: 日 &lt; 月 &lt; 火 &lt; 水 &lt; 木 &lt; 金 &lt; 土 # 曜日を順序付きfactor型で非省略 wday(x, label = TRUE, abbr = FALSE) #&gt; [1] 土曜日 #&gt; 7 Levels: 日曜日 &lt; 月曜日 &lt; 火曜日 &lt; 水曜日 &lt; 木曜日 &lt; ... &lt; 土曜日 # 曜日を月曜からスタートさせる wday(x, label = TRUE, abbr = FALSE, week_start = 1) #&gt; [1] 土曜日 #&gt; 7 Levels: 月曜日 &lt; 火曜日 &lt; 水曜日 &lt; 木曜日 &lt; 金曜日 &lt; ... &lt; 日曜日 セットしているlocaleにあわせて表示されます。自動的にやってくれるので便利です。 4.3 参照 Get/set weeks component of a date-time 週番号を取得する関数の説明 Get/set days component of a date-time 曜日を取得する関数wday()などの説明 "],
["05-interval.html", "lesson: 5 特定の期間を利用した処理 5.1 想定シナリオ 5.2 処理の実行 5.3 参照", " lesson: 5 特定の期間を利用した処理 ここでは、lesson2で準備したdf_logという仮想ログデータを用いて、一定期間での集計をまとめることを目指します。その中でlubridateのintervalオブジェクトと%within%演算子を説明します。 5.1 想定シナリオ lesson2で作成したアイテム購入ログデータを元に、1/16から1/31までを曜日別集計を行います: 期間内購入件数 期間内売上合計 期間内購入単価平均 この集計により、その期間での売上を検証することができます。 また、特定の期間とそれ以外の期間での比較を行います: 購入件数の比較 売上合計の比較 これにより、期間別の比較をすることができます。 5.2 処理の実行 5.2.1 パッケージ読み込み ここで使用するパッケージを読み込みます: library(tidyverse) library(lubridate) library(gridExtra) 5.2.2 データ読み込み lesson2で作成したcsvを読み込みます。readr::read_csv()を使います: df_log &lt;- read_csv(&quot;df_log.csv&quot;) #&gt; Parsed with column specification: #&gt; cols( #&gt; stamp = col_datetime(format = &quot;&quot;), #&gt; id = col_integer(), #&gt; item = col_character(), #&gt; value = col_double() #&gt; ) 5.2.3 データハンドリングと可視化 5.2.3.1 特定期間を取り出す 特定の期間でどれだけ売上があったかを集計してデータセットにします。基本的な流れは以下のとおりです: 特定期間を表すietervalオブジェクトを作成 特定期間のデータを抽出 各種集計を実施 実際のRのコードは以下のようになります: # intervalオブジェクトを生成 target_interval &lt;- interval( start = ymd(&quot;2018-1-16&quot;), end = ymd(&quot;2018-1-31&quot;) ) # ターゲット期間のみを取り出して集計 # 指定が効いているのを確認するため日別集計 df_log_interval &lt;- df_log %&gt;% filter(stamp %within% target_interval) %&gt;% mutate(date = date(stamp)) %&gt;% group_by(date) %&gt;% summarise( n_buy = n(), value_buy = sum(value), mean_buy = mean(value) ) この処理を行ったデータセットは以下のようになります: knitr::kable(head(df_log_interval, 10)) date n_buy value_buy mean_buy 2018-01-16 198 86600 437.3737 2018-01-17 192 70000 364.5833 2018-01-18 176 62200 353.4091 2018-01-19 214 76200 356.0748 2018-01-20 201 69900 347.7612 2018-01-21 202 78300 387.6238 2018-01-22 197 60600 307.6142 2018-01-23 195 73900 378.9744 2018-01-24 195 78900 404.6154 2018-01-25 193 81700 423.3161 このデータを元にggplot2で可視化してみます: # 指定区間を取り出した範囲で可視化 p_int_date &lt;- ggplot(df_log_interval) p_int_date1 &lt;- p_int_date + geom_line(aes(x = date, y = n_buy)) p_int_date2 &lt;- p_int_date + geom_line(aes(x = date, y = value_buy)) p_int_date3 &lt;- p_int_date + geom_line(aes(x = date, y = mean_buy)) grid.arrange(p_int_date1, p_int_date2, p_int_date3, nrow = 2) ついでに、指定期間との比較をやってみます # 区間指定の応用。一定期間とそれ以外で検証 # filterではなくif_elseでmutateする # 3つ以上ならcase_whenでパターンを準備すればOK df_log_interval_comp &lt;- df_log %&gt;% mutate(target = if_else( stamp %within% target_interval, &quot;target&quot;, &quot;other&quot; )) %&gt;% mutate(hour = hour(stamp)) %&gt;% group_by(hour, target) %&gt;% summarise( n_buy = n(), value_buy = sum(value), mean_buy = mean(value) ) この処理を行ったデータセットは以下のようになります: knitr::kable(head(df_log_interval_comp, 10)) hour target n_buy value_buy mean_buy 0 other 270 92500 342.5926 0 target 125 60900 487.2000 1 other 293 112900 385.3242 1 target 131 50300 383.9695 2 other 288 101500 352.4306 2 target 125 39800 318.4000 3 other 284 116700 410.9155 3 target 107 27300 255.1402 4 other 270 94200 348.8889 4 target 115 44700 388.6957 このデータを元にggplot2で可視化してみます: p_int_comp_date &lt;- ggplot(df_log_interval_comp) p_int_comp_date1 &lt;- p_int_comp_date + geom_boxplot(aes(x = target, y = mean_buy, color = target)) + coord_flip() p_int_comp_date2 &lt;- p_int_comp_date + geom_line(aes(x = hour, y = mean_buy, color = target)) grid.arrange(p_int_comp_date1, p_int_comp_date2, nrow = 2) 5.2.4 解説 今回のポイントは、「この日時からこの日時まで」という特定の期間を示すintervalオブジェクトです。 lubridateパッケージには、独自でintervalクラスが実装されています: # 使う日時データを準備 x1 &lt;- ymd_hms(&quot;2018-02-23 17:50:00&quot;) x2 &lt;- ymd_hms(&quot;2018-02-25 17:50:00&quot;) # intervalオブジェクトを作成 x_i &lt;- interval( start = x1, end = x1 + days(1) ) # そのまま出してみる x_i #&gt; [1] 2018-02-23 17:50:00 UTC--2018-02-24 17:50:00 UTC # 開始日時を取得 int_start(x_i) #&gt; [1] &quot;2018-02-23 17:50:00 UTC&quot; # 終了日時を取得 int_end(x_i) #&gt; [1] &quot;2018-02-24 17:50:00 UTC&quot; # 時間の幅を取得 int_length(x_i) #&gt; [1] 86400 # interval作成用の%--%演算子 x1 %--% x2 #&gt; [1] 2018-02-23 17:50:00 UTC--2018-02-25 17:50:00 UTC intervalオブジェクトは時間的な幅を秒単位で保持し、それに属性(attribute)で開始日時とタイムゾーン、そしてclass情報を付与しています: # 中身を強制的に出力 # 1日は86400秒 cat(x_i) #&gt; 86400 # 属性を出力してみる attributes(x_i) #&gt; $start #&gt; [1] &quot;2018-02-23 17:50:00 UTC&quot; #&gt; #&gt; $tzone #&gt; [1] &quot;UTC&quot; #&gt; #&gt; $class #&gt; [1] &quot;Interval&quot; #&gt; attr(,&quot;package&quot;) #&gt; [1] &quot;lubridate&quot; このあたりが理解できていれば、lesson2-4の内容を応用していろいろいじれることはわかるかと思います。このintervalオブジェクトに関する便利な関数がlubridateパッケージに準備してあります: # intervalを準備 x_i1 &lt;- interval(ymd(&quot;2018-01-01&quot;), ymd(&quot;2018-01-31&quot;)) x_i2 &lt;- interval(ymd(&quot;2018-01-16&quot;), ymd(&quot;2018-02-16&quot;)) x_i3 &lt;- interval(ymd(&quot;2018-02-01&quot;), ymd(&quot;2018-02-28&quot;)) # intervalをずらす # 第二引数には時間的な幅(duration(), days()など) int_shift(x_i1, days(5)) #&gt; [1] 2018-01-06 UTC--2018-02-05 UTC # 開始と終了を反転 x_i1_flip &lt;- int_flip(x_i1) x_i1_flip #&gt; [1] 2018-01-31 UTC--2018-01-01 UTC # 開始と終了を整える(順番をきれいにする) int_standardize(x_i1_flip) #&gt; [1] 2018-01-01 UTC--2018-01-31 UTC # 2つの区間が重なっているかどう(オーバーラップ)か判定 # これはオーバーラップしているのでTRUE int_overlaps(x_i1, x_i2) #&gt; [1] TRUE # これはオーバーラップしてないのでFALSE int_overlaps(x_i1, x_i3) #&gt; [1] FALSE # 2つのintervalで、開始and/or終了が同じかどうか(align)判定 # 説明用に新たにintervalを準備 x_i4 &lt;- interval(ymd(&quot;2018-01-01&quot;), ymd(&quot;2018-02-16&quot;)) # x_i4の開始はx_i1の開始と揃っているので、これはTRUE int_aligns(x_i4, x_i1) #&gt; [1] TRUE # x_i4の終了はx_i2の終了と揃っているので、これもTRUE int_aligns(x_i4, x_i2) #&gt; [1] TRUE # x_i4はx_i3の開始とも終了とも揃っていないので、これはFALSE int_aligns(x_i4, x_i3) #&gt; [1] FALSE # 日時ベクトルの要素で、その差分を利用してintervalベクトルを作成 # 説明用に日付のベクトルを生成 dates &lt;- now() + days(1:3) dates #&gt; [1] &quot;2018-02-26 12:51:32 JST&quot; &quot;2018-02-27 12:51:32 JST&quot; #&gt; [3] &quot;2018-02-28 12:51:32 JST&quot; # 差分でintervalベクトルを生成 # この場合、3つの日時から区間をつくるので長さが2になる int_diff(dates) #&gt; [1] 2018-02-26 12:51:32 JST--2018-02-27 12:51:32 JST #&gt; [2] 2018-02-27 12:51:32 JST--2018-02-28 12:51:32 JST また、「あるinterval/日時が、ある区間に含まれるかどうか」を判定する演算子として、lubridateには%within%が準備してあります。 # 説明用にintervalを準備 x_i1 &lt;- interval(ymd(&quot;2018-01-01&quot;), ymd(&quot;2018-01-31&quot;)) x_i2 &lt;- interval(ymd(&quot;2018-01-16&quot;), ymd(&quot;2018-01-31&quot;)) x_i3 &lt;- interval(ymd(&quot;2018-01-16&quot;), ymd(&quot;2018-02-16&quot;)) # %within%演算子のテスト # これは含まれるのでTRUE ymd(&quot;2018-01-10&quot;) %within% x_i1 #&gt; [1] TRUE # これは含まれないのでFALSE ymd(&quot;2018-02-10&quot;) %within% x_i1 #&gt; [1] FALSE # intervalでの比較 # これは含まれるのでTRUE x_i2 %within% x_i1 #&gt; [1] TRUE # これは(オーバーラップしてるけけど)内包しているわけではないのでFALSE x_i3 %within% x_i1 #&gt; [1] FALSE # この演算子は「左が右に含まれるかどうか」を判定 # なので、これはFALSE x_i1 %within% x_i2 #&gt; [1] FALSE 演算子の右にはintervalオブジェクトしか使えませんので注意してください。 5.3 参照 Utilities for creation and manipulation of Interval objects intervalオブジェクトを作成・操作する関数の説明 Interval class intervalクラスの説明 Tests whether a date or interval falls within an interval %within%演算子の説明 "]
]
